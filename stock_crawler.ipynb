{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "import random\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import psycopg2\n",
    "from selenium import webdriver\n",
    "\n",
    "def log():\n",
    "    formatter = logging.Formatter('%(asctime)s - [%(levelname)s] - %(message)s')\n",
    "    hdlr = logging.StreamHandler()\n",
    "    hdlr.setFormatter(formatter)\n",
    "    logger = logging.getLogger() \n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(hdlr)\n",
    "    return logger\n",
    "\n",
    "class Initial:\n",
    "    def __init__(self):\n",
    "        self.url_pool = {'info':'https://goodinfo.tw/StockInfo/StockBzPerformance.asp?STOCK_ID='\n",
    "                         ,'YoY':'https://goodinfo.tw/StockInfo/StockDividendPolicy.asp?STOCK_ID='\n",
    "                         ,'price':'https://www.twse.com.tw/exchangeReport/STOCK_DAY_AVG?response=html&date=&stockNo='\n",
    "                        }\n",
    "        self.driver = webdriver.Chrome('G:\\Anaconda\\Tools\\chromedriver.exe')\n",
    "        \n",
    "class Flag(Initial):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.id = 0\n",
    "        super(Flag, self).__init__()\n",
    "        \n",
    "    def search(self):\n",
    "        logger.info('Start to search stock id.')\n",
    "        for key, value in self.url_pool.items():\n",
    "            if key == 'info':\n",
    "                list_sql = \"select stock_id from stock_info where flag in ('1','2');\"\n",
    "                __db = Database()\n",
    "                exist = __db.get(list_sql)\n",
    "                while self.id < 10000:\n",
    "                    self.id += 1\n",
    "                    s_id = str(self.id).zfill(4)\n",
    "                    if s_id not in exist[0]:\n",
    "                        url = value + s_id\n",
    "                        logger.info('parse {}'.format(url))\n",
    "                        self.driver.get(url)\n",
    "                        soup = BeautifulSoup(self.driver.page_source,'lxml')\n",
    "                        hk_sql = \"delete from stock_info where stock_id = '{}';\".format(s_id)\n",
    "                        try:\n",
    "                            name = soup.select('.std_tbl tr > td')[1].text.split('\\xa0')[1]\n",
    "                            dml_sql = \"insert into stock_info (stock_id, company, flag) values('{}','{}',3);\".format(s_id,name)\n",
    "                        except:\n",
    "                            dml_sql = \"insert into stock_info (stock_id, company, flag) values('{}',null,0);\".format(s_id)\n",
    "                \n",
    "                        try:\n",
    "                            __db.run(hk_sql)\n",
    "                            __db.run(dml_sql)\n",
    "                            __db.logout()\n",
    "                        except:\n",
    "                            logger.error('Database error')\n",
    "                        \n",
    "                        if '瀏覽量異常' in str(soup):\n",
    "                            f.note(self.id)\n",
    "                            break\n",
    "                        \n",
    "                        t = random.randint(30,60)\n",
    "                        time.sleep(t+120)\n",
    "            \n",
    "        self.driver.quit()\n",
    "    \n",
    "    @staticmethod\n",
    "    def note(count):\n",
    "        try:\n",
    "            __n = Database()\n",
    "            if count == 0:\n",
    "                __n.run(\"delete from check_blocking;\")\n",
    "                note_sql = \"insert into check_blocking select 'start', current_timestamp;\"\n",
    "                __n.run(note_sql)\n",
    "            else:\n",
    "                note_sql = \"insert into check_blocking select '{}', current_timestamp;\".format(count)\n",
    "                __n.run(note_sql)\n",
    "\n",
    "            __n.logout()\n",
    "        except:\n",
    "            logger.error('Database error')\n",
    "            \n",
    "class Crawler(Initial):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Crawler, self).__init__()\n",
    "        self.db = Database()\n",
    "        self.id_pool = self.db.get(\"select stock_id, company from stock_info where flag='1' order by stock_id asc;\")\n",
    "        \n",
    "    def yoy(self):\n",
    "        for key, value in self.url_pool.items():\n",
    "            if key == 'YoY':\n",
    "                logger.info('Start to parse YoY information of stocks.')\n",
    "                for number in self.id_pool:\n",
    "                    stock_id = number[0]\n",
    "                    url = value + stock_id\n",
    "                    logger.info('parse {}'.format(url))\n",
    "                    __e = Extract(url)\n",
    "                    \n",
    "                    per = __e.data('.std_tbl > tbody > tr:nth-of-type(5) > td:nth-of-type(6)', 'float','a')\n",
    "                    pbr = __e.data('.std_tbl > tbody > tr:nth-of-type(5) > td:nth-of-type(7)', 'float','a')\n",
    "                    self.db.run(\"delete from stock_per_pbr where stock_id = '{}';\".format(stock_id))\n",
    "                    self.db.run(\"insert into stock_per_pbr values('{}', {}, {});\".format(stock_id, per, pbr))\n",
    "                    \n",
    "                    for count in range(1,5):\n",
    "                        cash_dividend = __e.data('.solid_1_padding_4_0_tbl > tbody > tr:nth-of-type({}) \\\n",
    "                                                         > td:nth-of-type(4)'.format(count), 'float','a')\n",
    "                        stock_dividend = __e.data('.solid_1_padding_4_0_tbl > tbody > tr:nth-of-type({}) \\\n",
    "                                                         > td:nth-of-type(7)'.format(count), 'float','a')\n",
    "                        eps = __e.data('.solid_1_padding_4_0_tbl > tbody > tr:nth-of-type({}) \\\n",
    "                                               > td:nth-of-type(23)'.format(count), 'float','a')\n",
    "                        year = __e.data('.solid_1_padding_4_0_tbl > tbody > tr:nth-of-type({}) \\\n",
    "                                                > td:nth-of-type(22)'.format(count))\n",
    "                        spls_aption = __e.data('.solid_1_padding_4_0_tbl > tbody > tr:nth-of-type({}) \\\n",
    "                                                       > td:nth-of-type(26)'.format(count), 'float','a')\n",
    "                        self.db.run(\"delete from stock_yoy_revenue where stock_id = '{}' and year = '{}';\".format(stock_id, year))\n",
    "                        self.db.run(\"insert into stock_yoy_revenue values('{}','{}',\\\n",
    "                              {},{},{},{})\".format(stock_id, year, eps, stock_dividend, cash_dividend, spls_aption))\n",
    "                                    \n",
    "                    t = random.randint(30,60)\n",
    "                    time.sleep(t+180)\n",
    "                \n",
    "                self.db.logout()\n",
    "                logger.info('The parsing of stocks\\' YoY information finished.')\n",
    "\n",
    "        self.driver.quit()\n",
    "    \n",
    "    def price(self):\n",
    "        \n",
    "        for pri_key, pri_value in self.url_pool.items():\n",
    "            if pri_key == 'price':\n",
    "                logger.info('Start to parse price of stocks.')\n",
    "                for pri_number in self.id_pool:\n",
    "                    stock_no = pri_number[0]\n",
    "                    pri_date = 'date=' + datetime.strftime(datetime.today(),'%Y%m%d')\n",
    "                    pri_url = pri_value.replace('date=',pri_date) + stock_no\n",
    "                    logger.info('parse {}'.format(pri_url))\n",
    "                    __e = Extract(pri_url)\n",
    "                    trading_day = __e.data('table > tbody > tr > td:nth-of-type(1)')\n",
    "                    \n",
    "                    for c in range(0, len(trading_day)-1):\n",
    "                        ad = __e.data('table > tbody > tr > td:nth-of-type(1)', 'convert_to_AD', 'b', c)\n",
    "                        p = __e.data('table > tbody > tr > td:nth-of-type(2)', 'float', 'b', c)\n",
    "                        self.db.run(\"delete from stock_price where stock_id='{}' and trading_day='{}';\".format(stock_no, ad))\n",
    "                        self.db.run(\"insert into stock_price values('{}','{}',{});\".format(stock_no, ad, p))\n",
    "                    \n",
    "                    t = random.randint(30,60)\n",
    "                    time.sleep(t+150)\n",
    "                \n",
    "                self.db.logout()\n",
    "                logger.info('The parsing of stocks\\' price finished.')\n",
    "        \n",
    "        self.driver.quit()\n",
    "\n",
    "class Extract(Initial):\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        super(Extract, self).__init__()\n",
    "        self.driver.get(url)\n",
    "        self.soup = BeautifulSoup(self.driver.page_source,'lxml')\n",
    "    \n",
    "    def data(self, selector, transfer=None, type=None, count=None):\n",
    "        if transfer == 'float' and type == 'a':\n",
    "            try:\n",
    "                return float(self.soup.select(selector)[0].text)\n",
    "            except:\n",
    "                return 'null'\n",
    "        elif transfer == 'float' and type == 'b':\n",
    "            try:\n",
    "                return float(self.soup.select(selector)[count].text)\n",
    "            except:\n",
    "                return -1\n",
    "        elif transfer == 'convert_to_AD':\n",
    "            try:\n",
    "                ad = self.soup.select(selector)[count].text\n",
    "                pat = ad.split('/')[0]\n",
    "                new_pat = str(int(pat) + 1911)\n",
    "                return ad.replace(pat, new_pat)\n",
    "            except:\n",
    "                return '9999'\n",
    "        else:\n",
    "            return self.soup.select(selector)        \n",
    "                \n",
    "class Database:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.con = psycopg2.connect(database='stock', user='postgres', password='postgres', host='localhost', port='5432')\n",
    "        self.cur = self.con.cursor()\n",
    "    \n",
    "    def run(self, sql):\n",
    "        self.cur.execute(sql)\n",
    "        self.con.commit()\n",
    "        \n",
    "    def get(self, sql):\n",
    "        self.cur.execute(sql)\n",
    "        data = self.cur.fetchall()\n",
    "        self.con.commit()\n",
    "        return data   # return tuple\n",
    "    \n",
    "    def logout(self):\n",
    "        try:\n",
    "            self.con.close()\n",
    "        except:\n",
    "            logger.info('already logged out!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    logger = log()\n",
    "    c = Crawler()\n",
    "    c.yoy()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
